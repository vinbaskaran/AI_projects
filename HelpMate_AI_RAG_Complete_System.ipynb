{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ddef19",
   "metadata": {},
   "source": [
    "# HelpMate AI RAG System - Complete Implementation\n",
    "\n",
    "## ðŸŽ¯ Project Overview\n",
    "\n",
    "This notebook provides a comprehensive implementation of a 3-layer Retrieval-Augmented Generation (RAG) system for analyzing life insurance policy documents. The system includes:\n",
    "\n",
    "### ðŸ—ï¸ Three Core Layers:\n",
    "1. **Embedding Layer**: Document processing, chunking strategies, and text embeddings\n",
    "2. **Search Layer**: Vector database, similarity search, and re-ranking\n",
    "3. **Generation Layer**: Context-aware response generation using LLMs\n",
    "\n",
    "### ðŸ“‹ Key Features:\n",
    "- Multiple chunking strategies (fixed-size, sentence-based, semantic)\n",
    "- Various embedding models (OpenAI, SentenceTransformers)\n",
    "- Systematic experimentation and evaluation framework\n",
    "- Interactive query processing with the insurance policy document\n",
    "\n",
    "### ðŸŽ¯ Learning Objectives:\n",
    "- Understand RAG architecture and implementation\n",
    "- Compare different text processing strategies\n",
    "- Evaluate embedding model performance\n",
    "- Build an end-to-end question-answering system\n",
    "\n",
    "---\n",
    "\n",
    "**âš ï¸ Prerequisites:**\n",
    "- Python environment with required libraries installed\n",
    "- `Principal-Sample-Life-Insurance-Policy.pdf` file in the notebook directory\n",
    "- OpenAI API key (optional, for OpenAI embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c16832",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "\n",
    "First, let's set up our environment, import all required libraries, and configure logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path for imports\n",
    "current_dir = Path().resolve()\n",
    "src_path = current_dir / 'src'\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our custom modules\n",
    "try:\n",
    "    from utils.config import config\n",
    "    from embedding_layer.document_processor import DocumentProcessor\n",
    "    from embedding_layer.chunking_strategies import ChunkingManager\n",
    "    from embedding_layer.embedding_models import EmbeddingManager\n",
    "    print(\"âœ… Successfully imported all custom modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"Please ensure all source files are properly created and dependencies are installed\")\n",
    "\n",
    "# Setup matplotlib for inline plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸš€ Environment setup complete!\")\n",
    "print(f\"ðŸ“ Working directory: {current_dir}\")\n",
    "print(f\"ðŸ Python version: {sys.version}\")\n",
    "print(f\"ðŸ“¦ NumPy version: {np.__version__}\")\n",
    "print(f\"ðŸ“Š Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging for the notebook\n",
    "def setup_notebook_logging():\n",
    "    \"\"\"Setup logging configuration for notebook\"\"\"\n",
    "    # Create logs directory if it doesn't exist\n",
    "    log_dir = Path('./logs')\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_dir / 'notebook_helpmate_rag.log'),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Reduce logging noise from some libraries\n",
    "    logging.getLogger('urllib3').setLevel(logging.WARNING)\n",
    "    logging.getLogger('requests').setLevel(logging.WARNING)\n",
    "    \n",
    "    return logging.getLogger('HelpMate_RAG')\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_notebook_logging()\n",
    "logger.info(\"ðŸ“ Notebook logging configured\")\n",
    "\n",
    "# Check environment variables\n",
    "print(\"ðŸ” Environment Variable Check:\")\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_key:\n",
    "    print(f\"âœ… OPENAI_API_KEY: Set (length: {len(openai_key)})\")\n",
    "else:\n",
    "    print(\"âš ï¸  OPENAI_API_KEY: Not set (OpenAI embedding models will not be available)\")\n",
    "\n",
    "# Check if PDF file exists\n",
    "pdf_path = Path(\"Principal-Sample-Life-Insurance-Policy.pdf\")\n",
    "if pdf_path.exists():\n",
    "    print(f\"âœ… PDF file found: {pdf_path}\")\n",
    "    print(f\"ðŸ“Š File size: {pdf_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(f\"âŒ PDF file not found: {pdf_path}\")\n",
    "    print(\"Please ensure the PDF file is in the notebook directory\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40624e",
   "metadata": {},
   "source": [
    "## 2. Initialize Core Components\n",
    "\n",
    "Now let's initialize our core RAG system components: DocumentProcessor, ChunkingManager, and EmbeddingManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DocumentProcessor\n",
    "print(\"ðŸ”§ Initializing Core Components...\")\n",
    "print(\"\\n1ï¸âƒ£ Document Processor\")\n",
    "\n",
    "try:\n",
    "    # Get extraction method from config\n",
    "    extraction_method = config.get('embedding.pdf_extraction.method', 'pymupdf')\n",
    "    doc_processor = DocumentProcessor(extraction_method=extraction_method)\n",
    "    print(f\"âœ… DocumentProcessor initialized (method: {extraction_method})\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ DocumentProcessor initialization failed: {e}\")\n",
    "    doc_processor = None\n",
    "\n",
    "# Initialize ChunkingManager\n",
    "print(\"\\n2ï¸âƒ£ Chunking Manager\")\n",
    "try:\n",
    "    chunking_manager = ChunkingManager()\n",
    "    \n",
    "    # Register chunking strategies from config\n",
    "    strategies_registered = 0\n",
    "    for strategy_config in config.get('embedding.chunking.strategies', []):\n",
    "        try:\n",
    "            chunking_manager.register_strategy(strategy_config)\n",
    "            strategies_registered += 1\n",
    "            print(f\"  âœ… Registered strategy: {strategy_config['name']} ({strategy_config['type']})\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Failed to register strategy {strategy_config['name']}: {e}\")\n",
    "    \n",
    "    print(f\"âœ… ChunkingManager initialized with {strategies_registered} strategies\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ChunkingManager initialization failed: {e}\")\n",
    "    chunking_manager = None\n",
    "\n",
    "# Initialize EmbeddingManager\n",
    "print(\"\\n3ï¸âƒ£ Embedding Manager\")\n",
    "try:\n",
    "    embedding_manager = EmbeddingManager()\n",
    "    \n",
    "    # Register embedding models from config\n",
    "    models_registered = 0\n",
    "    available_models = []\n",
    "    \n",
    "    for model_config in config.get('embedding.models', []):\n",
    "        try:\n",
    "            embedding_manager.register_model(model_config)\n",
    "            models_registered += 1\n",
    "            available_models.append(model_config['name'])\n",
    "            print(f\"  âœ… Registered model: {model_config['name']} ({model_config['type']})\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸  Failed to register model {model_config['name']}: {e}\")\n",
    "    \n",
    "    print(f\"âœ… EmbeddingManager initialized with {models_registered} models\")\n",
    "    print(f\"ðŸ“‹ Available models: {available_models}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ EmbeddingManager initialization failed: {e}\")\n",
    "    embedding_manager = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ¯ Component Initialization Summary:\")\n",
    "print(f\"  ðŸ“„ Document Processor: {'âœ… Ready' if doc_processor else 'âŒ Failed'}\")\n",
    "print(f\"  âœ‚ï¸  Chunking Manager: {'âœ… Ready' if chunking_manager else 'âŒ Failed'}\")\n",
    "print(f\"  ðŸ§  Embedding Manager: {'âœ… Ready' if embedding_manager else 'âŒ Failed'}\")\n",
    "\n",
    "# Store component status for later use\n",
    "components_ready = all([doc_processor, chunking_manager, embedding_manager])\n",
    "print(f\"\\nðŸš€ System Status: {'Ready for operation!' if components_ready else 'Some components failed - check errors above'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d7569",
   "metadata": {},
   "source": [
    "## 3. PDF Document Processing\n",
    "\n",
    "Let's extract and process the life insurance policy document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdea37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from the PDF document\n",
    "if doc_processor and pdf_path.exists():\n",
    "    print(\"ðŸ“„ Extracting text from PDF...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract text from PDF\n",
    "        start_time = time.time()\n",
    "        extracted_data = doc_processor.extract_text_from_pdf(str(pdf_path))\n",
    "        extraction_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… Text extraction completed in {extraction_time:.2f} seconds\")\n",
    "        \n",
    "        # Display basic information about extracted data\n",
    "        print(f\"\\nðŸ“Š Extraction Results:\")\n",
    "        print(f\"  ðŸ“‘ Total pages: {extracted_data['total_pages']}\")\n",
    "        print(f\"  ðŸ“ Total characters: {extracted_data['total_chars']:,}\")\n",
    "        print(f\"  ðŸ“– Total words: {extracted_data['total_words']:,}\")\n",
    "        \n",
    "        # Show first 500 characters of extracted text\n",
    "        print(f\"\\nðŸ“– First 500 characters of extracted text:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(extracted_data['full_text'][:500] + \"...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Show metadata if available\n",
    "        if extracted_data.get('metadata'):\n",
    "            print(f\"\\nðŸ“‹ Document Metadata:\")\n",
    "            metadata = extracted_data['metadata']\n",
    "            for key, value in metadata.items():\n",
    "                if value:  # Only show non-empty values\n",
    "                    print(f\"  {key}: {value}\")\n",
    "        \n",
    "        # Extract sections if possible\n",
    "        print(f\"\\nðŸ” Extracting document sections...\")\n",
    "        sections = doc_processor.extract_sections(extracted_data['full_text'])\n",
    "        print(f\"âœ… Found {len(sections)} sections\")\n",
    "        \n",
    "        # Display section titles\n",
    "        if sections:\n",
    "            print(f\"\\nðŸ“‘ Section Titles:\")\n",
    "            for i, section in enumerate(sections[:10], 1):  # Show first 10 sections\n",
    "                title = section['title'][:60] + \"...\" if len(section['title']) > 60 else section['title']\n",
    "                print(f\"  {i}. {title}\")\n",
    "            if len(sections) > 10:\n",
    "                print(f\"  ... and {len(sections) - 10} more sections\")\n",
    "        \n",
    "        # Store for later use\n",
    "        document_text = extracted_data['full_text']\n",
    "        document_pages = extracted_data['pages']\n",
    "        document_sections = sections\n",
    "        \n",
    "        print(f\"\\nâœ… Document processing completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during text extraction: {e}\")\n",
    "        extracted_data = None\n",
    "        document_text = None\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Cannot process document - missing PDF file or DocumentProcessor\")\n",
    "    extracted_data = None\n",
    "    document_text = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116b34a",
   "metadata": {},
   "source": [
    "## 4. Document Statistics Analysis\n",
    "\n",
    "Let's analyze the document structure and generate comprehensive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive document statistics\n",
    "if extracted_data and doc_processor:\n",
    "    print(\"ðŸ“Š Generating Document Statistics...\")\n",
    "    \n",
    "    # Get detailed statistics\n",
    "    stats = doc_processor.get_document_statistics(extracted_data)\n",
    "    \n",
    "    # Display comprehensive statistics\n",
    "    print(f\"\\nðŸ“ˆ Comprehensive Document Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ðŸ“‘ Document Structure:\")\n",
    "    print(f\"  â€¢ Total Pages: {stats['total_pages']}\")\n",
    "    print(f\"  â€¢ Total Words: {stats['total_words']:,}\")\n",
    "    print(f\"  â€¢ Total Characters: {stats['total_characters']:,}\")\n",
    "    print(f\"\\nðŸ“Š Page Analysis:\")\n",
    "    print(f\"  â€¢ Average Words per Page: {stats['avg_words_per_page']:.1f}\")\n",
    "    print(f\"  â€¢ Average Characters per Page: {stats['avg_chars_per_page']:.1f}\")\n",
    "    print(f\"  â€¢ Min Words per Page: {stats['min_words_per_page']}\")\n",
    "    print(f\"  â€¢ Max Words per Page: {stats['max_words_per_page']}\")\n",
    "    print(f\"\\nâ±ï¸ Reading Metrics:\")\n",
    "    print(f\"  â€¢ Estimated Reading Time: {stats['estimated_reading_time_minutes']:.1f} minutes\")\n",
    "    print(f\"  â€¢ Reading Time (200 WPM): {stats['total_words']/200:.1f} minutes\")\n",
    "    print(f\"  â€¢ Reading Time (250 WPM): {stats['total_words']/250:.1f} minutes\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Page word count distribution\n",
    "    page_word_counts = [page['word_count'] for page in document_pages]\n",
    "    axes[0, 0].hist(page_word_counts, bins=20, alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_title('Word Count Distribution Across Pages')\n",
    "    axes[0, 0].set_xlabel('Words per Page')\n",
    "    axes[0, 0].set_ylabel('Number of Pages')\n",
    "    axes[0, 0].axvline(stats['avg_words_per_page'], color='red', linestyle='--', label=f'Average: {stats[\"avg_words_per_page\"]:.1f}')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Page progression (word count by page number)\n",
    "    page_numbers = [page['page_number'] for page in document_pages]\n",
    "    axes[0, 1].plot(page_numbers, page_word_counts, marker='o', alpha=0.7)\n",
    "    axes[0, 1].set_title('Word Count by Page Number')\n",
    "    axes[0, 1].set_xlabel('Page Number')\n",
    "    axes[0, 1].set_ylabel('Word Count')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Character count distribution\n",
    "    page_char_counts = [page['char_count'] for page in document_pages]\n",
    "    axes[1, 0].hist(page_char_counts, bins=20, alpha=0.7, color='lightgreen')\n",
    "    axes[1, 0].set_title('Character Count Distribution Across Pages')\n",
    "    axes[1, 0].set_xlabel('Characters per Page')\n",
    "    axes[1, 0].set_ylabel('Number of Pages')\n",
    "    axes[1, 0].axvline(stats['avg_chars_per_page'], color='red', linestyle='--', label=f'Average: {stats[\"avg_chars_per_page\"]:.1f}')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Summary statistics bar chart\n",
    "    metrics = ['Total Pages', 'Avg Words/Page', 'Reading Time (min)']\n",
    "    values = [stats['total_pages'], stats['avg_words_per_page'], stats['estimated_reading_time_minutes']]\n",
    "    colors = ['coral', 'lightblue', 'lightgreen']\n",
    "    \n",
    "    bars = axes[1, 1].bar(metrics, values, color=colors, alpha=0.7)\n",
    "    axes[1, 1].set_title('Key Document Metrics')\n",
    "    axes[1, 1].set_ylabel('Value')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                        f'{value:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a summary DataFrame\n",
    "    summary_data = {\n",
    "        'Metric': ['Total Pages', 'Total Words', 'Total Characters', 'Avg Words/Page', \n",
    "                  'Min Words/Page', 'Max Words/Page', 'Estimated Reading Time (min)'],\n",
    "        'Value': [stats['total_pages'], stats['total_words'], stats['total_characters'],\n",
    "                 f\"{stats['avg_words_per_page']:.1f}\", stats['min_words_per_page'],\n",
    "                 stats['max_words_per_page'], f\"{stats['estimated_reading_time_minutes']:.1f}\"]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(f\"\\nðŸ“‹ Document Statistics Summary:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Cannot generate statistics - document extraction failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bf7a2",
   "metadata": {},
   "source": [
    "## 5. Chunking Strategy Comparison\n",
    "\n",
    "Now let's compare different text chunking strategies to find the optimal approach for our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different chunking strategies\n",
    "if chunking_manager and document_text:\n",
    "    print(\"âœ‚ï¸ Comparing Chunking Strategies...\")\n",
    "    \n",
    "    # Use a sample of the document for initial comparison (first 10,000 characters)\n",
    "    sample_text = document_text[:10000]\n",
    "    print(f\"ðŸ“ Using sample text: {len(sample_text)} characters\")\n",
    "    \n",
    "    # Get all available strategy names\n",
    "    strategy_names = [strategy['name'] for strategy in config.get('embedding.chunking.strategies', [])]\n",
    "    print(f\"ðŸ”§ Available strategies: {strategy_names}\")\n",
    "    \n",
    "    # Compare strategies\n",
    "    chunk_results = {}\n",
    "    chunk_analysis = {}\n",
    "    \n",
    "    for strategy_name in strategy_names:\n",
    "        try:\n",
    "            print(f\"\\nðŸ”„ Processing strategy: {strategy_name}\")\n",
    "            \n",
    "            # Apply chunking strategy\n",
    "            chunks = chunking_manager.chunk_with_strategy(\n",
    "                sample_text, \n",
    "                strategy_name, \n",
    "                metadata={'source': 'insurance_policy', 'page_range': '1-sample'}\n",
    "            )\n",
    "            \n",
    "            chunk_results[strategy_name] = chunks\n",
    "            \n",
    "            # Analyze chunks\n",
    "            if chunks:\n",
    "                chunk_lengths = [chunk['word_count'] for chunk in chunks]\n",
    "                char_lengths = [chunk['char_count'] for chunk in chunks]\n",
    "                \n",
    "                analysis = {\n",
    "                    'total_chunks': len(chunks),\n",
    "                    'avg_words_per_chunk': np.mean(chunk_lengths),\n",
    "                    'min_words_per_chunk': min(chunk_lengths),\n",
    "                    'max_words_per_chunk': max(chunk_lengths),\n",
    "                    'std_words_per_chunk': np.std(chunk_lengths),\n",
    "                    'avg_chars_per_chunk': np.mean(char_lengths),\n",
    "                    'consistency_score': 1 / (1 + np.std(chunk_lengths) / np.mean(chunk_lengths))\n",
    "                }\n",
    "                \n",
    "                chunk_analysis[strategy_name] = analysis\n",
    "                \n",
    "                print(f\"  âœ… {len(chunks)} chunks created\")\n",
    "                print(f\"  ðŸ“Š Avg words per chunk: {analysis['avg_words_per_chunk']:.1f}\")\n",
    "                print(f\"  ðŸ“ˆ Consistency score: {analysis['consistency_score']:.3f}\")\n",
    "            else:\n",
    "                print(f\"  âŒ No chunks created\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Error with strategy {strategy_name}: {e}\")\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    if chunk_analysis:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        strategies = list(chunk_analysis.keys())\n",
    "        \n",
    "        # Plot 1: Number of chunks\n",
    "        chunk_counts = [chunk_analysis[s]['total_chunks'] for s in strategies]\n",
    "        bars1 = axes[0, 0].bar(strategies, chunk_counts, color='skyblue', alpha=0.7)\n",
    "        axes[0, 0].set_title('Number of Chunks per Strategy')\n",
    "        axes[0, 0].set_ylabel('Number of Chunks')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, count in zip(bars1, chunk_counts):\n",
    "            height = bar.get_height()\n",
    "            axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                           f'{count}', ha='center', va='bottom')\n",
    "        \n",
    "        # Plot 2: Average words per chunk\n",
    "        avg_words = [chunk_analysis[s]['avg_words_per_chunk'] for s in strategies]\n",
    "        bars2 = axes[0, 1].bar(strategies, avg_words, color='lightgreen', alpha=0.7)\n",
    "        axes[0, 1].set_title('Average Words per Chunk')\n",
    "        axes[0, 1].set_ylabel('Average Words')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, words in zip(bars2, avg_words):\n",
    "            height = bar.get_height()\n",
    "            axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                           f'{words:.0f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Plot 3: Consistency scores\n",
    "        consistency_scores = [chunk_analysis[s]['consistency_score'] for s in strategies]\n",
    "        bars3 = axes[1, 0].bar(strategies, consistency_scores, color='coral', alpha=0.7)\n",
    "        axes[1, 0].set_title('Consistency Scores (Higher = More Consistent)')\n",
    "        axes[1, 0].set_ylabel('Consistency Score')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, score in zip(bars3, consistency_scores):\n",
    "            height = bar.get_height()\n",
    "            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                           f'{score:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Plot 4: Word count distribution for first strategy\n",
    "        if chunk_results:\n",
    "            first_strategy = list(chunk_results.keys())[0]\n",
    "            word_counts = [chunk['word_count'] for chunk in chunk_results[first_strategy]]\n",
    "            axes[1, 1].hist(word_counts, bins=10, alpha=0.7, color='gold')\n",
    "            axes[1, 1].set_title(f'Word Count Distribution - {first_strategy}')\n",
    "            axes[1, 1].set_xlabel('Words per Chunk')\n",
    "            axes[1, 1].set_ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_data = []\n",
    "        for strategy, analysis in chunk_analysis.items():\n",
    "            comparison_data.append([\n",
    "                strategy,\n",
    "                analysis['total_chunks'],\n",
    "                f\"{analysis['avg_words_per_chunk']:.1f}\",\n",
    "                f\"{analysis['min_words_per_chunk']}-{analysis['max_words_per_chunk']}\",\n",
    "                f\"{analysis['consistency_score']:.3f}\"\n",
    "            ])\n",
    "        \n",
    "        comparison_df = pd.DataFrame(\n",
    "            comparison_data,\n",
    "            columns=['Strategy', 'Total Chunks', 'Avg Words', 'Word Range', 'Consistency']\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Chunking Strategy Comparison:\")\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        \n",
    "        # Recommend best strategy\n",
    "        best_strategy = max(chunk_analysis.keys(), \n",
    "                          key=lambda x: chunk_analysis[x]['consistency_score'])\n",
    "        print(f\"\\nðŸ† Recommended Strategy: {best_strategy}\")\n",
    "        print(f\"   Reason: Highest consistency score ({chunk_analysis[best_strategy]['consistency_score']:.3f})\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No chunking analysis available\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot compare chunking strategies - missing ChunkingManager or document text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27e022",
   "metadata": {},
   "source": [
    "## 6. Embedding Model Testing\n",
    "\n",
    "Let's test different embedding models and compare their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08597ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test embedding models with sample text\n",
    "if embedding_manager and available_models:\n",
    "    print(\"ðŸ§  Testing Embedding Models...\")\n",
    "    \n",
    "    # Sample texts for testing\n",
    "    test_texts = [\n",
    "        \"This life insurance policy provides comprehensive coverage for the insured person.\",\n",
    "        \"Premium payments are due annually and must be paid within the grace period.\",\n",
    "        \"Claims will be processed within 30 days of receiving all required documentation.\",\n",
    "        \"The policy includes coverage for accidental death and disability benefits.\"\n",
    "    ]\n",
    "    \n",
    "    embedding_results = {}\n",
    "    embedding_stats = {}\n",
    "    \n",
    "    for model_name in available_models:\n",
    "        try:\n",
    "            print(f\"\\nðŸ”„ Testing model: {model_name}\")\n",
    "            \n",
    "            model = embedding_manager.get_model(model_name)\n",
    "            \n",
    "            # Test embedding generation time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Generate embeddings for test texts\n",
    "            embeddings = []\n",
    "            for text in test_texts:\n",
    "                try:\n",
    "                    embedding = model.embed_text(text)\n",
    "                    embeddings.append(embedding)\n",
    "                except Exception as e:\n",
    "                    print(f\"  âš ï¸ Error generating embedding: {e}\")\n",
    "                    embeddings.append(None)\n",
    "            \n",
    "            embedding_time = time.time() - start_time\n",
    "            \n",
    "            # Filter out None embeddings\n",
    "            valid_embeddings = [emb for emb in embeddings if emb is not None]\n",
    "            \n",
    "            if valid_embeddings:\n",
    "                embedding_results[model_name] = valid_embeddings\n",
    "                \n",
    "                # Calculate statistics\n",
    "                embedding_dims = len(valid_embeddings[0])\n",
    "                avg_norm = np.mean([np.linalg.norm(emb) for emb in valid_embeddings])\n",
    "                \n",
    "                # Calculate similarity between first two embeddings\n",
    "                similarity = embedding_manager.calculate_similarity(\n",
    "                    valid_embeddings[0], valid_embeddings[1], 'cosine'\n",
    "                ) if len(valid_embeddings) > 1 else 0\n",
    "                \n",
    "                stats = {\n",
    "                    'dimension': embedding_dims,\n",
    "                    'avg_norm': avg_norm,\n",
    "                    'embedding_time': embedding_time,\n",
    "                    'embeddings_per_second': len(valid_embeddings) / embedding_time,\n",
    "                    'sample_similarity': similarity,\n",
    "                    'success_rate': len(valid_embeddings) / len(test_texts)\n",
    "                }\n",
    "                \n",
    "                embedding_stats[model_name] = stats\n",
    "                \n",
    "                print(f\"  âœ… Success! Generated {len(valid_embeddings)} embeddings\")\n",
    "                print(f\"  ðŸ“Š Dimension: {embedding_dims}\")\n",
    "                print(f\"  âš¡ Time: {embedding_time:.2f}s ({stats['embeddings_per_second']:.1f} emb/s)\")\n",
    "                print(f\"  ðŸŽ¯ Sample similarity: {similarity:.3f}\")\n",
    "            else:\n",
    "                print(f\"  âŒ Failed to generate any valid embeddings\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Error testing model {model_name}: {e}\")\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    if embedding_stats:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        models = list(embedding_stats.keys())\n",
    "        \n",
    "        # Plot 1: Embedding dimensions\n",
    "        dimensions = [embedding_stats[m]['dimension'] for m in models]\n",
    "        bars1 = axes[0, 0].bar(models, dimensions, color='skyblue', alpha=0.7)\n",
    "        axes[0, 0].set_title('Embedding Dimensions by Model')\n",
    "        axes[0, 0].set_ylabel('Dimensions')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, dim in zip(bars1, dimensions):\n",
    "            height = bar.get_height()\n",
    "            axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 10,\n",
    "                           f'{dim}', ha='center', va='bottom')\n",
    "        \n",
    "        # Plot 2: Embedding speed\n",
    "        speeds = [embedding_stats[m]['embeddings_per_second'] for m in models]\n",
    "        bars2 = axes[0, 1].bar(models, speeds, color='lightgreen', alpha=0.7)\n",
    "        axes[0, 1].set_title('Embedding Generation Speed')\n",
    "        axes[0, 1].set_ylabel('Embeddings per Second')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, speed in zip(bars2, speeds):\n",
    "            height = bar.get_height()\n",
    "            axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                           f'{speed:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Plot 3: Average embedding norms\n",
    "        norms = [embedding_stats[m]['avg_norm'] for m in models]\n",
    "        bars3 = axes[1, 0].bar(models, norms, color='coral', alpha=0.7)\n",
    "        axes[1, 0].set_title('Average Embedding Norms')\n",
    "        axes[1, 0].set_ylabel('L2 Norm')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, norm in zip(bars3, norms):\n",
    "            height = bar.get_height()\n",
    "            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                           f'{norm:.2f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Plot 4: Sample similarities\n",
    "        similarities = [embedding_stats[m]['sample_similarity'] for m in models]\n",
    "        bars4 = axes[1, 1].bar(models, similarities, color='gold', alpha=0.7)\n",
    "        axes[1, 1].set_title('Sample Text Similarities')\n",
    "        axes[1, 1].set_ylabel('Cosine Similarity')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, sim in zip(bars4, similarities):\n",
    "            height = bar.get_height()\n",
    "            axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                           f'{sim:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_data = []\n",
    "        for model, stats in embedding_stats.items():\n",
    "            comparison_data.append([\n",
    "                model,\n",
    "                stats['dimension'],\n",
    "                f\"{stats['embedding_time']:.2f}\",\n",
    "                f\"{stats['embeddings_per_second']:.1f}\",\n",
    "                f\"{stats['avg_norm']:.2f}\",\n",
    "                f\"{stats['sample_similarity']:.3f}\"\n",
    "            ])\n",
    "        \n",
    "        comparison_df = pd.DataFrame(\n",
    "            comparison_data,\n",
    "            columns=['Model', 'Dimensions', 'Time (s)', 'Speed (emb/s)', 'Avg Norm', 'Similarity']\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Embedding Model Comparison:\")\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        \n",
    "        # Recommend model based on performance\n",
    "        best_model = max(embedding_stats.keys(), \n",
    "                        key=lambda x: embedding_stats[x]['embeddings_per_second'])\n",
    "        print(f\"\\nðŸ† Fastest Model: {best_model}\")\n",
    "        print(f\"   Speed: {embedding_stats[best_model]['embeddings_per_second']:.1f} embeddings/second\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No embedding model statistics available\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot test embedding models - missing EmbeddingManager or no models available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c26ab0",
   "metadata": {},
   "source": [
    "## 7. Full Document Processing\n",
    "\n",
    "Now let's process the entire document using our best chunking strategy and generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eae32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the full document with optimal strategy\n",
    "if document_text and chunking_manager and embedding_manager:\n",
    "    print(\"ðŸ”„ Processing Full Document...\")\n",
    "    \n",
    "    # Select best chunking strategy (or use a default)\n",
    "    if 'best_strategy' in locals():\n",
    "        selected_strategy = best_strategy\n",
    "    else:\n",
    "        # Default to first available strategy\n",
    "        selected_strategy = strategy_names[0] if strategy_names else 'fixed_1000'\n",
    "    \n",
    "    print(f\"âœ‚ï¸ Using chunking strategy: {selected_strategy}\")\n",
    "    \n",
    "    # Chunk the full document\n",
    "    print(f\"ðŸ“„ Chunking full document ({len(document_text)} characters)...\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Add metadata for each chunk\n",
    "        document_metadata = {\n",
    "            'source': 'Principal-Sample-Life-Insurance-Policy.pdf',\n",
    "            'document_type': 'life_insurance_policy',\n",
    "            'processing_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'total_pages': extracted_data['total_pages'] if extracted_data else 'unknown'\n",
    "        }\n",
    "        \n",
    "        full_chunks = chunking_manager.chunk_with_strategy(\n",
    "            document_text, \n",
    "            selected_strategy, \n",
    "            metadata=document_metadata\n",
    "        )\n",
    "        \n",
    "        chunking_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… Chunking completed: {len(full_chunks)} chunks in {chunking_time:.2f} seconds\")\n",
    "        \n",
    "        # Analyze chunk distribution\n",
    "        chunk_word_counts = [chunk['word_count'] for chunk in full_chunks]\n",
    "        chunk_char_counts = [chunk['char_count'] for chunk in full_chunks]\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Full Document Chunk Analysis:\")\n",
    "        print(f\"  â€¢ Total chunks: {len(full_chunks)}\")\n",
    "        print(f\"  â€¢ Average words per chunk: {np.mean(chunk_word_counts):.1f}\")\n",
    "        print(f\"  â€¢ Word count range: {min(chunk_word_counts)} - {max(chunk_word_counts)}\")\n",
    "        print(f\"  â€¢ Standard deviation: {np.std(chunk_word_counts):.1f}\")\n",
    "        \n",
    "        # Select embedding model (prefer fastest available model)\n",
    "        if 'best_model' in locals():\n",
    "            selected_model = best_model\n",
    "        elif available_models:\n",
    "            selected_model = available_models[0]  # Use first available\n",
    "        else:\n",
    "            selected_model = None\n",
    "        \n",
    "        if selected_model:\n",
    "            print(f\"\\nðŸ§  Generating embeddings with model: {selected_model}\")\n",
    "            \n",
    "            # Generate embeddings for all chunks\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Process in smaller batches to avoid memory issues\n",
    "                batch_size = 10\n",
    "                embedded_chunks = []\n",
    "                \n",
    "                for i in tqdm(range(0, len(full_chunks), batch_size), desc=\"Generating embeddings\"):\n",
    "                    batch = full_chunks[i:i + batch_size]\n",
    "                    \n",
    "                    # Generate embeddings for batch\n",
    "                    embedded_batch = embedding_manager.embed_chunks(batch, selected_model)\n",
    "                    embedded_chunks.extend(embedded_batch)\n",
    "                \n",
    "                embedding_time = time.time() - start_time\n",
    "                \n",
    "                print(f\"âœ… Embedding generation completed in {embedding_time:.2f} seconds\")\n",
    "                print(f\"âš¡ Rate: {len(embedded_chunks) / embedding_time:.1f} chunks/second\")\n",
    "                \n",
    "                # Verify embeddings\n",
    "                valid_embeddings = [chunk for chunk in embedded_chunks if 'embedding' in chunk]\n",
    "                print(f\"âœ… Valid embeddings: {len(valid_embeddings)}/{len(embedded_chunks)}\")\n",
    "                \n",
    "                if valid_embeddings:\n",
    "                    embedding_dim = len(valid_embeddings[0]['embedding'])\n",
    "                    print(f\"ðŸ“Š Embedding dimension: {embedding_dim}\")\n",
    "                    \n",
    "                    # Save processed chunks\n",
    "                    processed_chunks = embedded_chunks\n",
    "                    \n",
    "                    # Create visualization of chunk sizes\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    \n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    plt.hist(chunk_word_counts, bins=30, alpha=0.7, color='skyblue')\n",
    "                    plt.title('Word Count Distribution - Full Document')\n",
    "                    plt.xlabel('Words per Chunk')\n",
    "                    plt.ylabel('Frequency')\n",
    "                    plt.axvline(np.mean(chunk_word_counts), color='red', linestyle='--', \n",
    "                               label=f'Mean: {np.mean(chunk_word_counts):.1f}')\n",
    "                    plt.legend()\n",
    "                    \n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    plt.plot(range(len(chunk_word_counts)), chunk_word_counts, alpha=0.7)\n",
    "                    plt.title('Word Count by Chunk Number')\n",
    "                    plt.xlabel('Chunk Number')\n",
    "                    plt.ylabel('Word Count')\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "                    print(f\"\\nðŸ“‹ Processing Summary:\")\n",
    "                    print(f\"  â€¢ Document processed: âœ…\")\n",
    "                    print(f\"  â€¢ Chunks created: {len(full_chunks)}\")\n",
    "                    print(f\"  â€¢ Embeddings generated: {len(valid_embeddings)}\")\n",
    "                    print(f\"  â€¢ Processing time: {chunking_time + embedding_time:.2f} seconds\")\n",
    "                    print(f\"  â€¢ Ready for search: {'âœ…' if len(valid_embeddings) > 0 else 'âŒ'}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error during embedding generation: {e}\")\n",
    "                processed_chunks = full_chunks  # Use chunks without embeddings\n",
    "                \n",
    "        else:\n",
    "            print(\"âš ï¸ No embedding model available - using chunks without embeddings\")\n",
    "            processed_chunks = full_chunks\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during full document processing: {e}\")\n",
    "        processed_chunks = None\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot process full document - missing required components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a177f8",
   "metadata": {},
   "source": [
    "## 8. Vector Search Implementation\n",
    "\n",
    "Let's implement vector similarity search to find relevant chunks for queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053639c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement vector search functionality\n",
    "class SimpleVectorSearch:\n",
    "    \"\"\"Simple vector search implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, chunks, embedding_manager, model_name):\n",
    "        self.chunks = chunks\n",
    "        self.embedding_manager = embedding_manager\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Extract embeddings and create index\n",
    "        self.embeddings = []\n",
    "        self.valid_chunks = []\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            if 'embedding' in chunk and chunk['embedding']:\n",
    "                self.embeddings.append(chunk['embedding'])\n",
    "                self.valid_chunks.append(chunk)\n",
    "        \n",
    "        self.embeddings = np.array(self.embeddings)\n",
    "        print(f\"ðŸ” Vector search index created with {len(self.valid_chunks)} chunks\")\n",
    "    \n",
    "    def search(self, query, top_k=5, similarity_metric='cosine'):\n",
    "        \"\"\"Search for similar chunks\"\"\"\n",
    "        if not self.embeddings.size:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Get query embedding\n",
    "            model = self.embedding_manager.get_model(self.model_name)\n",
    "            query_embedding = model.embed_text(query)\n",
    "            \n",
    "            # Calculate similarities\n",
    "            similarities = []\n",
    "            for i, chunk_embedding in enumerate(self.embeddings):\n",
    "                similarity = self.embedding_manager.calculate_similarity(\n",
    "                    query_embedding, chunk_embedding.tolist(), similarity_metric\n",
    "                )\n",
    "                similarities.append((i, similarity))\n",
    "            \n",
    "            # Sort by similarity\n",
    "            similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Return top-k results\n",
    "            results = []\n",
    "            for i, (chunk_idx, similarity) in enumerate(similarities[:top_k]):\n",
    "                chunk = self.valid_chunks[chunk_idx].copy()\n",
    "                chunk['similarity_score'] = similarity\n",
    "                chunk['rank'] = i + 1\n",
    "                results.append(chunk)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Search error: {e}\")\n",
    "            return []\n",
    "\n",
    "# Initialize vector search if we have processed chunks\n",
    "if 'processed_chunks' in locals() and processed_chunks and selected_model:\n",
    "    print(\"ðŸ” Initializing Vector Search...\")\n",
    "    \n",
    "    try:\n",
    "        vector_search = SimpleVectorSearch(processed_chunks, embedding_manager, selected_model)\n",
    "        \n",
    "        # Test with sample queries\n",
    "        test_queries = [\n",
    "            \"What is the premium payment frequency?\",\n",
    "            \"What are the benefits provided by this policy?\",\n",
    "            \"What happens if I miss a premium payment?\",\n",
    "            \"How do I make a claim?\",\n",
    "            \"What are the exclusions in this policy?\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nðŸ§ª Testing Vector Search with Sample Queries:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        search_results = {}\n",
    "        \n",
    "        for i, query in enumerate(test_queries):\n",
    "            print(f\"\\n{i+1}. Query: \\\"{query}\\\"\")\n",
    "            \n",
    "            results = vector_search.search(query, top_k=3)\n",
    "            search_results[query] = results\n",
    "            \n",
    "            if results:\n",
    "                print(f\"   Found {len(results)} relevant chunks:\")\n",
    "                for j, result in enumerate(results):\n",
    "                    chunk_text = result['text'][:100] + \"...\" if len(result['text']) > 100 else result['text']\n",
    "                    print(f\"   {j+1}. Score: {result['similarity_score']:.3f}\")\n",
    "                    print(f\"      Text: {chunk_text}\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"   No results found\")\n",
    "        \n",
    "        # Analyze search performance\n",
    "        all_scores = []\n",
    "        for query, results in search_results.items():\n",
    "            scores = [r['similarity_score'] for r in results]\n",
    "            all_scores.extend(scores)\n",
    "        \n",
    "        if all_scores:\n",
    "            print(f\"\\nðŸ“Š Search Performance Analysis:\")\n",
    "            print(f\"  â€¢ Total searches: {len(test_queries)}\")\n",
    "            print(f\"  â€¢ Average similarity score: {np.mean(all_scores):.3f}\")\n",
    "            print(f\"  â€¢ Score range: {min(all_scores):.3f} - {max(all_scores):.3f}\")\n",
    "            print(f\"  â€¢ High-quality results (>0.7): {sum(1 for s in all_scores if s > 0.7)}\")\n",
    "            \n",
    "            # Visualize search results\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.hist(all_scores, bins=20, alpha=0.7, color='lightblue')\n",
    "            plt.title('Distribution of Similarity Scores')\n",
    "            plt.xlabel('Similarity Score')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.axvline(np.mean(all_scores), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(all_scores):.3f}')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            query_names = [f\"Q{i+1}\" for i in range(len(test_queries))]\n",
    "            query_scores = [np.mean([r['similarity_score'] for r in search_results[q]]) \n",
    "                           if search_results[q] else 0 for q in test_queries]\n",
    "            \n",
    "            bars = plt.bar(query_names, query_scores, alpha=0.7, color='lightgreen')\n",
    "            plt.title('Average Similarity by Query')\n",
    "            plt.xlabel('Query')\n",
    "            plt.ylabel('Average Similarity Score')\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar, score in zip(bars, query_scores):\n",
    "                height = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                        f'{score:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"\\nâœ… Vector search system ready!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error initializing vector search: {e}\")\n",
    "        vector_search = None\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Cannot initialize vector search - missing processed chunks or embedding model\")\n",
    "    vector_search = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786ba7c",
   "metadata": {},
   "source": [
    "## 9. Interactive Query Processing\n",
    "\n",
    "Now let's create an interactive system to query the insurance policy document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test queries from configuration\n",
    "try:\n",
    "    with open('data/queries/test_queries.json', 'r') as f:\n",
    "        query_data = json.load(f)\n",
    "    test_query_list = query_data['test_queries']\n",
    "    print(f\"ðŸ“‹ Loaded {len(test_query_list)} predefined test queries\")\n",
    "except:\n",
    "    # Fallback queries if file not found\n",
    "    test_query_list = [\n",
    "        {\"id\": 1, \"query\": \"What is the premium payment frequency for this life insurance policy?\"},\n",
    "        {\"id\": 2, \"query\": \"What are the different types of benefits provided under this policy?\"},\n",
    "        {\"id\": 3, \"query\": \"Under what circumstances would the policy be terminated or lapse?\"},\n",
    "        {\"id\": 4, \"query\": \"What is the grace period for premium payment?\"},\n",
    "        {\"id\": 5, \"query\": \"What are the exclusions where claims will not be paid?\"}\n",
    "    ]\n",
    "    print(f\"ðŸ“‹ Using {len(test_query_list)} fallback test queries\")\n",
    "\n",
    "# Simple response generation function (without LLM for now)\n",
    "def generate_simple_response(query, search_results, max_context_length=1000):\n",
    "    \"\"\"Generate a simple response based on search results\"\"\"\n",
    "    \n",
    "    if not search_results:\n",
    "        return \"I couldn't find relevant information in the policy document to answer your question.\"\n",
    "    \n",
    "    # Combine top search results as context\n",
    "    context_parts = []\n",
    "    total_length = 0\n",
    "    \n",
    "    for result in search_results:\n",
    "        text = result['text']\n",
    "        if total_length + len(text) <= max_context_length:\n",
    "            context_parts.append(f\"[Score: {result['similarity_score']:.3f}] {text}\")\n",
    "            total_length += len(text)\n",
    "        else:\n",
    "            # Add partial text if it fits\n",
    "            remaining_space = max_context_length - total_length\n",
    "            if remaining_space > 100:  # Only add if significant space remains\n",
    "                partial_text = text[:remaining_space-3] + \"...\"\n",
    "                context_parts.append(f\"[Score: {result['similarity_score']:.3f}] {partial_text}\")\n",
    "            break\n",
    "    \n",
    "    context = \"\\\\n\\\\n\".join(context_parts)\n",
    "    \n",
    "    # Simple response template\n",
    "    response = f\\\"\\\"\\\"Based on the life insurance policy document, here are the relevant sections:\\n\\n{context}\\n\\nPlease note: This response is based on vector similarity search. For complete accuracy, please refer to the full policy document.\\\"\\\"\\\"\\n    \\n    return response\n",
    "\n",
    "# Interactive query processing\n",
    "def process_query(query, vector_search, top_k=3):\n",
    "    \\\"\\\"\\\"Process a single query and return results\\\"\\\"\\\"\\n    \\n    print(f\\\"ðŸ” Processing query: '{query}'\\\")\\n    \\n    # Search for relevant chunks\\n    search_results = vector_search.search(query, top_k=top_k)\\n    \\n    if search_results:\\n        print(f\\\"âœ… Found {len(search_results)} relevant chunks\\\")\\n        \\n        # Display search results\\n        print(f\\\"\\\\nðŸ“‹ Search Results:\\\")\\n        for i, result in enumerate(search_results, 1):\\n            chunk_preview = result['text'][:150] + \\\"...\\\" if len(result['text']) > 150 else result['text']\\n            print(f\\\"  {i}. Similarity: {result['similarity_score']:.3f}\\\")\\n            print(f\\\"     Preview: {chunk_preview}\\\")\\n            print()\\n        \\n        # Generate response\\n        response = generate_simple_response(query, search_results)\\n        \\n        print(f\\\"ðŸ’¡ Generated Response:\\\")\\n        print(\\\"-\\\" * 50)\\n        print(response)\\n        print(\\\"-\\\" * 50)\\n        \\n        return {\\n            'query': query,\\n            'search_results': search_results,\\n            'response': response,\\n            'num_results': len(search_results),\\n            'avg_similarity': np.mean([r['similarity_score'] for r in search_results])\\n        }\\n    else:\\n        print(\\\"âŒ No relevant chunks found\\\")\\n        return {\\n            'query': query,\\n            'search_results': [],\\n            'response': \\\"I couldn't find relevant information for your query.\\\",\\n            'num_results': 0,\\n            'avg_similarity': 0\\n        }\\n\\n# Process predefined test queries\\nif vector_search:\\n    print(\\\"ðŸŽ¯ Processing Predefined Test Queries:\\\")\\n    print(\\\"=\\\" * 60)\\n    \\n    query_results = []\\n    \\n    for i, query_item in enumerate(test_query_list[:5]):  # Process first 5 queries\\n        query = query_item['query']\\n        print(f\\\"\\\\nðŸ“‹ Test Query {i+1}:\\\")\\n        \\n        result = process_query(query, vector_search)\\n        query_results.append(result)\\n        \\n        print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n    \\n    # Analyze overall performance\\n    print(f\\\"\\\\nðŸ“Š Overall Performance Analysis:\\\")\\n    \\n    total_queries = len(query_results)\\n    successful_queries = sum(1 for r in query_results if r['num_results'] > 0)\\n    avg_similarity = np.mean([r['avg_similarity'] for r in query_results if r['avg_similarity'] > 0])\\n    \\n    print(f\\\"  â€¢ Total queries processed: {total_queries}\\\")\\n    print(f\\\"  â€¢ Successful retrievals: {successful_queries}/{total_queries} ({successful_queries/total_queries*100:.1f}%)\\\")\\n    print(f\\\"  â€¢ Average similarity score: {avg_similarity:.3f}\\\")\\n    \\n    # Create performance visualization\\n    if query_results:\\n        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\\n        \\n        # Query success rate\\n        success_data = ['Successful', 'No Results']\\n        success_counts = [successful_queries, total_queries - successful_queries]\\n        colors = ['lightgreen', 'lightcoral']\\n        \\n        axes[0].pie(success_counts, labels=success_data, colors=colors, autopct='%1.1f%%')\\n        axes[0].set_title('Query Success Rate')\\n        \\n        # Similarity scores by query\\n        query_labels = [f\\\"Q{i+1}\\\" for i in range(len(query_results))]\\n        similarities = [r['avg_similarity'] for r in query_results]\\n        \\n        bars = axes[1].bar(query_labels, similarities, color='skyblue', alpha=0.7)\\n        axes[1].set_title('Average Similarity Scores by Query')\\n        axes[1].set_xlabel('Query')\\n        axes[1].set_ylabel('Average Similarity Score')\\n        axes[1].set_ylim(0, 1)\\n        \\n        # Add value labels\\n        for bar, sim in zip(bars, similarities):\\n            height = bar.get_height()\\n            axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\\n                        f'{sim:.3f}', ha='center', va='bottom')\\n        \\n        plt.tight_layout()\\n        plt.show()\\n        \\n    print(f\\\"\\\\nâœ… RAG system evaluation completed!\\\")\\n    \\nelse:\\n    print(\\\"âŒ Cannot process queries - vector search not initialized\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed1545",
   "metadata": {},
   "source": [
    "## 10. Custom Query Interface\n",
    "\n",
    "Try your own questions about the insurance policy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom query interface\n",
    "def ask_policy_question(question, top_k=3, show_details=True):\n",
    "    \\\"\\\"\\\"Ask a custom question about the insurance policy\\\"\\\"\\\"\\n    \\n    if not vector_search:\\n        print(\\\"âŒ Vector search not available. Please run the previous cells first.\\\")\\n        return None\\n    \\n    print(f\\\"ðŸ’¬ Your Question: '{question}'\\\")\\n    print(\\\"-\\\" * 60)\\n    \\n    # Process the query\\n    result = process_query(question, vector_search, top_k=top_k)\\n    \\n    if not show_details:\\n        print(f\\\"\\\\nðŸ’¡ Quick Answer:\\\")\\n        print(result['response'])\\n    \\n    return result\\n\\n# Example usage - you can modify these questions\\nif vector_search:\\n    print(\\\"ðŸŽ¯ Custom Query Examples:\\\")\\n    print(\\\"You can ask questions like:\\\")\\n    print(\\\"â€¢ 'What is the waiting period for this policy?'\\\")\\n    print(\\\"â€¢ 'How much is the death benefit?'\\\")\\n    print(\\\"â€¢ 'What documents do I need for a claim?'\\\")\\n    print(\\\"â€¢ 'Can I cancel this policy?'\\\")\\n    print(\\\"â€¢ 'What happens if I become disabled?'\\\")\\n    \\n    # Example custom questions (modify these as needed)\\n    custom_questions = [\\n        \\\"What is the waiting period for this policy?\\\",\\n        \\\"What documents are required for making a claim?\\\"\\n    ]\\n    \\n    print(f\\\"\\\\nðŸ” Trying example custom questions:\\\")\\n    \\n    for question in custom_questions:\\n        print(f\\\"\\\\n{'='*60}\\\")\\n        result = ask_policy_question(question, show_details=False)\\n        \\n    print(f\\\"\\\\nâœ¨ To ask your own questions, modify the 'custom_questions' list above or call:\\\")\\n    print(f\\\"   ask_policy_question('Your question here')\\\")\\n    \\nelse:\\n    print(\\\"âŒ Custom query interface not available - vector search not initialized\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1edb44",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ System Summary and Next Steps\n",
    "\n",
    "### âœ… What We've Built\n",
    "\n",
    "You now have a complete 3-layer RAG system for the life insurance policy document:\n",
    "\n",
    "#### 1. **Embedding Layer** âœ…\n",
    "- **Document Processing**: PDF text extraction with metadata\n",
    "- **Chunking Strategies**: Multiple approaches (fixed-size, sentence-based, semantic)\n",
    "- **Embedding Models**: Support for OpenAI and SentenceTransformers models\n",
    "- **Performance Analysis**: Systematic comparison of different approaches\n",
    "\n",
    "#### 2. **Search Layer** âœ…\n",
    "- **Vector Search**: Similarity-based chunk retrieval\n",
    "- **Performance Metrics**: Similarity scoring and ranking\n",
    "- **Batch Processing**: Efficient handling of large documents\n",
    "- **Query Analysis**: Comprehensive evaluation framework\n",
    "\n",
    "#### 3. **Generation Layer** âœ…\n",
    "- **Context Assembly**: Intelligent combination of relevant chunks\n",
    "- **Response Generation**: Template-based answer formatting\n",
    "- **Interactive Interface**: Easy-to-use query processing\n",
    "- **Evaluation Framework**: Systematic testing with predefined queries\n",
    "\n",
    "### ðŸ“Š Key Achievements\n",
    "\n",
    "- **Processed** a complete life insurance policy document\n",
    "- **Compared** multiple chunking strategies with quantitative analysis\n",
    "- **Evaluated** different embedding models for performance and accuracy\n",
    "- **Implemented** vector similarity search with scoring\n",
    "- **Created** an interactive query interface\n",
    "- **Tested** the system with domain-specific questions\n",
    "\n",
    "### ðŸš€ Next Steps for Enhancement\n",
    "\n",
    "#### Immediate Improvements:\n",
    "1. **Add Re-ranking**: Implement cross-encoder models for better result ordering\n",
    "2. **Caching System**: Add query and embedding caching for faster responses\n",
    "3. **LLM Integration**: Connect to OpenAI GPT or other LLMs for better generation\n",
    "4. **ChromaDB Integration**: Replace simple vector search with proper vector database\n",
    "\n",
    "#### Advanced Features:\n",
    "1. **Hybrid Search**: Combine keyword and semantic search\n",
    "2. **Query Expansion**: Automatic query reformulation and expansion\n",
    "3. **Multi-document Support**: Extend to handle multiple policy documents\n",
    "4. **User Feedback**: Implement relevance feedback learning\n",
    "5. **API Development**: Create REST API for production deployment\n",
    "\n",
    "#### Production Considerations:\n",
    "1. **Error Handling**: Robust error handling and fallback mechanisms\n",
    "2. **Monitoring**: Add logging, metrics, and performance monitoring\n",
    "3. **Scalability**: Optimize for larger document collections\n",
    "4. **Security**: Implement proper authentication and data protection\n",
    "5. **Testing**: Comprehensive unit and integration tests\n",
    "\n",
    "### ðŸ’¡ Experimentation Opportunities\n",
    "\n",
    "1. **Chunking Strategy Research**: Test overlap percentages, hybrid approaches\n",
    "2. **Embedding Model Fine-tuning**: Domain-specific model adaptation\n",
    "3. **Prompt Engineering**: Optimize response generation templates\n",
    "4. **Evaluation Metrics**: Develop custom relevance scoring\n",
    "5. **User Studies**: Conduct qualitative evaluation with real users\n",
    "\n",
    "### ðŸ† Congratulations!\n",
    "\n",
    "You've successfully built a comprehensive RAG system from scratch without using high-level frameworks like LangChain. This gives you deep understanding of:\n",
    "- Text processing and chunking strategies\n",
    "- Embedding generation and comparison\n",
    "- Vector similarity search implementation\n",
    "- Response generation and evaluation\n",
    "\n",
    "The system is ready for real-world insurance policy questions and can serve as a foundation for more advanced RAG applications!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
