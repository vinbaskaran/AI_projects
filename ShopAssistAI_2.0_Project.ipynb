{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0982c19e",
      "metadata": {
        "id": "0982c19e"
      },
      "source": [
        "# Enhance ShopAssist AI (ShopAssist 2.0) - using Function Calling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcbcd148",
      "metadata": {
        "id": "dcbcd148"
      },
      "source": [
        "Dataset obtained from : https://drive.google.com/file/d/1Z4Qta-ZpYGc-jjFstJXckyJKIvoQXTJj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34d671dc",
      "metadata": {
        "id": "34d671dc"
      },
      "source": [
        "Starter Notebook obtained from: https://colab.research.google.com/drive/1T-a5WIcle8XhBS5aX5tzFbc2S3MwFnT1#scrollTo=ad9b47b8\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21c4e72b",
      "metadata": {
        "id": "21c4e72b"
      },
      "source": [
        "# Objective:\n",
        "\n",
        "\n",
        "* **Integrate Function Calling API:** Modify the existing architecture to leverage the Function Calling API's capabilities for improved performance. Scope out which layers can be removed and how the existing layers can be updated to handle the new approach.\n",
        "\n",
        "* **Refine Conversation Flow:** Enhance the chatbot's conversation flow by leveraging function calling. Make the interaction between the user and the chatbot more natural and dynamic.\n",
        "\n",
        "* **Document and Present:** Create comprehensive documentation that outlines the changes made, the integration process, and the benefits of using the Function Calling API. Prepare a presentation to showcase the enhancements.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "8mCxhv548Grp"
      },
      "id": "8mCxhv548Grp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "import os, json, ast\n",
        "import openai\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from google.colab import userdata\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "10r1LzEe8KDs"
      },
      "id": "10r1LzEe8KDs",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Igkpk4Ig8OJT"
      },
      "id": "Igkpk4Ig8OJT",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbceebf1"
      },
      "source": [
        "# Major functions behind the Chatbot - copy from starter notebook\n",
        "\n",
        "\n",
        "- `initialize_conversation()`: This initializes the variable conversation with the system message.\n",
        "- `get_chat_completions()`: This takes the ongoing conversation as the input and returns the response by the assistant\n",
        "- `moderation_check()`: This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, it ends the conversation.\n",
        "- `intent_confirmation_layer()`: This function takes the assistant's response and evaluates if the chatbot has captured the user's profile clearly. Specifically, this checks if the following properties for the user has been captured or not GPU intensity, Display quality, Portability, Multitasking, Processing speed, Budget\n",
        "- `dictionary_present()`: This function checks if the final understanding of user's profile is returned by the chatbot as a python dictionary or not. If there is a dictionary, it extracts the information as a Python dictionary.\n",
        "- `compare_laptops_with_user()`: This function compares the user's profile with the different laptops and come back with the top 3 recommendations.\n",
        "- `initialize_conv_reco()`: Initializes the recommendations conversation"
      ],
      "id": "bbceebf1"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "431f76f6"
      },
      "outputs": [],
      "source": [
        "def initialize_conversation():\n",
        "    '''\n",
        "    Returns a list [{\"role\": \"system\", \"content\": system_message}]\n",
        "    '''\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    example_user_dict = {'GPU intensity': \"high\",\n",
        "                        'Display quality':\"high\",\n",
        "                        'Portability': \"low\",\n",
        "                        'Multitasking': \"high\",\n",
        "                        'Processing speed': \"high\",\n",
        "                        'Budget': \"150000\"}\n",
        "\n",
        "    example_user_req = {'GPU intensity': \"_\",\n",
        "                        'Display quality': \"_\",\n",
        "                        'Portability': \"_\",\n",
        "                        'Multitasking': \"_\",\n",
        "                        'Processing speed': \"_\",\n",
        "                        'Budget': \"_\"}\n",
        "\n",
        "    system_message = f\"\"\"\n",
        "    You are an intelligent laptop gadget expert and your goal is to find the best laptop for a user.\n",
        "    You need to ask relevant questions and understand the user profile by analysing the user's responses.\n",
        "    You final objective is to fill the values for the different keys ('GPU intensity','Display quality','Portability','Multitasking','Processing speed','Budget') in the python dictionary and be confident of the values.\n",
        "    These key value pairs define the user's profile.\n",
        "    The python dictionary looks like this\n",
        "    {{'GPU intensity': 'values','Display quality': 'values','Portability': 'values','Multitasking': 'values','Processing speed': 'values','Budget': 'values'}}\n",
        "    The value for 'Budget' should be a numerical value extracted from the user's response.\n",
        "    The values for all keys, except 'Budget', should be 'low', 'medium', or 'high' based on the importance of the corresponding keys, as stated by user.\n",
        "    All the values in the example dictionary are only representative values.\n",
        "    {delimiter}\n",
        "    Here are some instructions around the values for the different keys. If you do not follow this, you'll be heavily penalised:\n",
        "    - The values for all keys, except 'Budget', should strictly be either 'low', 'medium', or 'high' based on the importance of the corresponding keys, as stated by user.\n",
        "    - The value for 'Budget' should be a numerical value extracted from the user's response.\n",
        "    - 'Budget' value needs to be greater than or equal to 25000 INR. If the user says less than that, please mention that there are no laptops in that range.\n",
        "    - Do not randomly assign values to any of the keys.\n",
        "    - The values need to be inferred from the user's response.\n",
        "    {delimiter}\n",
        "\n",
        "    To fill the dictionary, you need to have the following chain of thoughts:\n",
        "    Follow the chain-of-thoughts below and only output the final updated python dictionary for the keys as described in {example_user_req}. \\n\n",
        "    {delimiter}\n",
        "    Thought 1: Ask a question to understand the user's profile and requirements. \\n\n",
        "    If their primary use for the laptop is unclear. Ask followup questions to understand their needs.\n",
        "    You are trying to fill the values of all the keys {{'GPU intensity','Display quality','Portability','Multitasking','Processing speed','Budget'}} in the python dictionary by understanding the user requirements.\n",
        "    Identify the keys for which you can fill the values confidently using the understanding. \\n\n",
        "    Remember the instructions around the values for the different keys.\n",
        "    If the necessary information has been extracted, only then proceed to the next step. \\n\n",
        "    Otherwise, rephrase the question to capture their profile clearly. \\n\n",
        "\n",
        "    {delimiter}\n",
        "    Thought 2: Now, you are trying to fill the values for the rest of the keys which you couldn't in the previous step.\n",
        "    Remember the instructions around the values for the different keys.\n",
        "    Ask questions you might have for all the keys to strengthen your understanding of the user's profile.\n",
        "    If yes, move to the next Thought. If no, ask question on the keys whose values you are unsure of. \\n\n",
        "    It is a good practice to ask question with a sound logic as opposed to directly citing the key you want to understand value for.\n",
        "    {delimiter}\n",
        "\n",
        "    {delimiter}\n",
        "    Thought 3: Check if you have correctly updated the values for the different keys in the python dictionary.\n",
        "    If you are not confident about any of the values, ask clarifying questions.\n",
        "    {delimiter}\n",
        "\n",
        "    {delimiter}\n",
        "    Here is a sample conversation between the user and assistant:\n",
        "    User: \"Hi, I am an editor.\"\n",
        "    Assistant: \"Great! As an editor, you likely require a laptop that can handle demanding tasks. Hence, the laptop should have high multitasking capability. You would also need a high end display for better visuals and editing. May I know what kind of work do you primarily focus on? Are you more involved in video editing, photo editing, or both? Understanding the specific type of editing work will help me tailor my recommendations accordingly. Let me know if my understanding is correct until now.\"\n",
        "    User: \"I primarily work with After Effects.\"\n",
        "    Assistant: \"Thank you for providing that information. Working with After Effects involves working with graphics, animations, and rendering, which will require high GPU. Do you work with high-resolution media files, such as 4K videos or RAW photos? Understanding your file sizes will help determine the storage capacity and processing power needed.\"\n",
        "    User: \"Yes, sometimes I work with 4K videos as well.\"\n",
        "    Assistant: \"Thank you for the information. Processing 4K vidoes will require a good processor and high GPU. I think we have already determined earlier that you need a high GPU. To ensure I have a complete understanding of your needs, I have one more question: Are you frequently on the go and require a laptop that is lightweight and easy to carry, or do you primarily work from a stationary location?\"\n",
        "    User: \"Yes, sometimes I travel but do not carry my laptop.\"\n",
        "    Assistant:\"Could you kindly let me know your budget for the laptop? This will help me find options that fit within your price range while meeting the specified requirements.\"\n",
        "    User: \"my max budget is 1.5lakh inr\"\n",
        "    Assistant: \"{example_user_dict}\"\n",
        "    {delimiter}\n",
        "\n",
        "    Start with a short welcome message and encourage the user to share their requirements.\n",
        "    \"\"\"\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    # conversation = system_message\n",
        "    return conversation"
      ],
      "id": "431f76f6"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "e5c799b4"
      },
      "outputs": [],
      "source": [
        "def moderation_check(user_input):\n",
        "    # Call the OpenAI API to perform moderation on the user's input.\n",
        "    response = openai.moderations.create(input=user_input)\n",
        "\n",
        "    print(response)\n",
        "\n",
        "    # Extract the moderation result from the API response.\n",
        "    moderation_output = response.results[0].flagged\n",
        "    # Check if the input was flagged by the moderation system.\n",
        "    if response.results[0].flagged == True:\n",
        "        # If flagged, return \"Flagged\"\n",
        "        return \"Flagged\"\n",
        "    else:\n",
        "        # If not flagged, return \"Not Flagged\"\n",
        "        return \"Not Flagged\""
      ],
      "id": "e5c799b4"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "w1o5KuBeONhF"
      },
      "outputs": [],
      "source": [
        "def intent_confirmation_layer(response_assistant):\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    allowed_values = {'low','medium','high'}\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a senior evaluator who has an eye for detail.The input text will contain a user requirement captured through 6 keys.\n",
        "    You are provided an input. You need to evaluate if the input text has the following keys:\n",
        "    {{\n",
        "    'GPU intensity': 'values',\n",
        "    'Display quality':'values',\n",
        "    'Portability':'values',\n",
        "    'Multitasking':'values',\n",
        "    'Processing speed':'values',\n",
        "    'Budget':'number'\n",
        "    }}\n",
        "    The values for the keys should only be from the allowed values: {allowed_values}.\n",
        "    The 'Budget' key can take only a numerical value.\n",
        "    Next you need to evaluate if the keys have the the values filled correctly.\n",
        "    Only output a one-word string in JSON format at the key 'result' - Yes/No.\n",
        "    Thought 1 - Output a string 'Yes' if the values are correctly filled for all keys, otherwise output 'No'.\n",
        "    Thought 2 - If the answer is No, mention the reason in the key 'reason'.\n",
        "    THought 3 - Think carefully before the answering.\n",
        "    \"\"\"\n",
        "\n",
        "    messages=[{\"role\": \"system\", \"content\":prompt },\n",
        "              {\"role\": \"user\", \"content\":f\"\"\"Here is the input: {response_assistant}\"\"\" }]\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "                                    model=\"gpt-3.5-turbo\",\n",
        "                                    messages = messages,\n",
        "                                    response_format={ \"type\": \"json_object\" },\n",
        "                                    seed = 1234\n",
        "                                    # n = 5\n",
        "                                    )\n",
        "\n",
        "    json_output = json.loads(response.choices[0].message.content)\n",
        "\n",
        "    return json_output"
      ],
      "id": "w1o5KuBeONhF"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KjZlut6U2p_e"
      },
      "outputs": [],
      "source": [
        "def dictionary_present(response):\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    user_req = {'GPU intensity': 'high',\n",
        "                'Display quality': 'high',\n",
        "                'Portability': 'medium',\n",
        "                'Multitasking': 'high',\n",
        "                'Processing speed': 'high',\n",
        "                'Budget': '200000'}\n",
        "\n",
        "    prompt = f\"\"\"You are a python expert. You are provided an input.\n",
        "            You have to check if there is a python dictionary present in the string.\n",
        "            It will have the following format {user_req}.\n",
        "            Your task is to just extract the relevant values from the input and return only the python dictionary in JSON format.\n",
        "            The output should match the format as {user_req}.\n",
        "\n",
        "            {delimiter}\n",
        "            Make sure that the value of budget is also present in the user input. ###\n",
        "            The output should contain the exact keys and values as present in the input.\n",
        "            Ensure the keys and values are in the given format:\n",
        "            {{\n",
        "            'GPU intensity': 'low/medium/high ',\n",
        "            'Display quality':'low/medium/high',\n",
        "            'Portability':'low/medium/high',\n",
        "            'Multitasking':'low/medium/high',\n",
        "            'Processing speed':'low/medium/high',\n",
        "            'Budget':'numerical value'\n",
        "            }}\n",
        "            Here are some sample input output pairs for better understanding:\n",
        "            {delimiter}\n",
        "            input 1: - GPU intensity: low - Display quality: high - Portability: low - Multitasking: high - Processing speed: medium - Budget: 50,000 INR\n",
        "            output 1: {{'GPU intensity': 'low', 'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '50000'}}\n",
        "\n",
        "            input 2: {{'GPU intensity':     'low', 'Display quality':     'low', 'Portability':    'medium', 'Multitasking': 'medium', 'Processing speed': 'low', 'Budget': '90,000'}}\n",
        "            output 2: {{'GPU intensity': 'low', 'Display quality': 'low', 'Portability': 'medium', 'Multitasking': 'medium', 'Processing speed': 'low', 'Budget': '90000'}}\n",
        "\n",
        "            input 3: Here is your user profile 'GPU intensity': 'high','Display quality': 'high','Portability': 'medium','Multitasking': 'high','Processing speed': 'high','Budget': '200000 INR'\n",
        "            output 3: {{'GPU intensity': 'high','Display quality': 'high','Portability': 'medium','Multitasking': 'high','Processing speed': 'high','Budget': '200000'}}\n",
        "            {delimiter}\n",
        "            \"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\":prompt },\n",
        "                {\"role\": \"user\", \"content\":f\"\"\"Here is the user input: {response}\"\"\" }]\n",
        "\n",
        "    confirmation = get_chat_completions(messages, json_format = True)\n",
        "\n",
        "    return confirmation"
      ],
      "id": "KjZlut6U2p_e"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "240d34cc"
      },
      "outputs": [],
      "source": [
        "def product_map_layer(laptop_description):\n",
        "    delimiter = \"#####\"\n",
        "\n",
        "    lap_spec = {\n",
        "        \"GPU intensity\":\"(Type of the Graphics Processor)\",\n",
        "        \"Display quality\":\"(Display Type, Screen Resolution, Display Size)\",\n",
        "        \"Portability\":\"(Laptop Weight)\",\n",
        "        \"Multitasking\":\"(RAM Size)\",\n",
        "        \"Processing speed\":\"(CPU Type, Core, Clock Speed)\"\n",
        "    }\n",
        "\n",
        "    values = {'low','medium','high'}\n",
        "\n",
        "    prompt=f\"\"\"\n",
        "    You are a Laptop Specifications Classifier whose job is to extract the key features of laptops and classify them as per their requirements.\n",
        "    To analyze each laptop, perform the following steps:\n",
        "    Step 1: Extract the laptop's primary features from the description {laptop_description}\n",
        "    Step 2: Store the extracted features in {lap_spec} \\\n",
        "    Step 3: Classify each of the items in {lap_spec} into {values} based on the following rules: \\\n",
        "    {delimiter}\n",
        "    GPU Intensity:\n",
        "    - low: <<< if GPU is entry-level such as an integrated graphics processor or entry-level dedicated graphics like Intel UHD >>> , \\n\n",
        "    - medium: <<< if mid-range dedicated graphics like M1, AMD Radeon, Intel Iris >>> , \\n\n",
        "    - high: <<< high-end dedicated graphics like Nvidia RTX >>> , \\n\n",
        "\n",
        "    Display Quality:\n",
        "    - low: <<< if resolution is below Full HD (e.g., 1366x768). >>> , \\n\n",
        "    - medium: <<< if Full HD resolution (1920x1080) or higher. >>> , \\n\n",
        "    - high: <<< if High-resolution display (e.g., 4K, Retina) with excellent color accuracy and features like HDR support. >>> \\n\n",
        "\n",
        "    Portability:\n",
        "    - high: <<< if laptop weight is less than 1.51 kg >>> , \\n\n",
        "    - medium: <<< if laptop weight is between 1.51 kg and 2.51 kg >>> , \\n\n",
        "    - low: <<< if laptop weight is greater than 2.51 kg >>> \\n\n",
        "\n",
        "    Multitasking:\n",
        "    - low: <<< If RAM size is 8 GB, 12 GB >>> , \\n\n",
        "    - medium: <<< if RAM size is 16 GB >>> , \\n\n",
        "    - high: <<< if RAM size is 32 GB, 64 GB >>> \\n\n",
        "\n",
        "    Processing Speed:\n",
        "    - low: <<< if entry-level processors like Intel Core i3, AMD Ryzen 3 >>> , \\n\n",
        "    - medium: <<< if Mid-range processors like Intel Core i5, AMD Ryzen 5 >>> , \\n\n",
        "    - high: <<< if High-performance processors like Intel Core i7, AMD Ryzen 7 or higher >>> \\n\n",
        "    {delimiter}\n",
        "\n",
        "    {delimiter}\n",
        "    Here is input output pair for few-shot learning:\n",
        "    input 1: \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\"\n",
        "    output 1: {{'GPU intensity': 'medium','Display quality':'medium','Portability':'medium','Multitasking':'high','Processing speed':'medium'}}\n",
        "\n",
        "    {delimiter}\n",
        "    ### Strictly don't keep any other text in the values of the JSON dictionary other than low or medium or high ###\n",
        "    \"\"\"\n",
        "    input = f\"\"\"Follow the above instructions step-by-step and output the dictionary in JSON format {lap_spec} for the following laptop {laptop_description}.\"\"\"\n",
        "    #see that we are using the Completion endpoint and not the Chatcompletion endpoint\n",
        "    messages=[{\"role\": \"system\", \"content\":prompt },{\"role\": \"user\",\"content\":input}]\n",
        "\n",
        "    response = get_chat_completions(messages, json_format = True)\n",
        "\n",
        "    #   response = openai.chat.completions.create(\n",
        "    #     model=\"gpt-3.5-turbo-0125\",\n",
        "    #     messages=[{\"role\": \"system\", \"content\":prompt },{\"role\": \"user\",\"content\":input}],\n",
        "    #     response_format={ \"type\": \"json_object\" }\n",
        "    #     # max_tokens = 2000,\n",
        "    #     )\n",
        "\n",
        "    # response = json.loads(response)\n",
        "    return response"
      ],
      "id": "240d34cc"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "c9bd0233",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "##extract product info\n",
        "laptop_df= pd.read_csv('laptop_data.csv')\n",
        "\n",
        "## Create a new column \"laptop_feature\" that contains the dictionary of the product features\n",
        "laptop_df['laptop_feature'] = laptop_df['Description'].apply(lambda x: product_map_layer(x))"
      ],
      "id": "c9bd0233"
    },
    {
      "cell_type": "code",
      "source": [
        "laptop_df.to_csv(\"updated_laptop.csv\",index=False,header = True)"
      ],
      "metadata": {
        "id": "dC-SHFpb_e_G"
      },
      "id": "dC-SHFpb_e_G",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_laptops_with_user(user_requirements):\n",
        "    laptop_df = pd.read_csv('updated_laptop.csv')\n",
        "\n",
        "    # Extracting the budget value from user_requirements and converting it to an integer\n",
        "    budget = int(user_requirements.get('Budget', '0').replace(',', '').split()[0])\n",
        "    # budget\n",
        "    # # Creating a copy of the DataFrame and filtering laptops based on the budget\n",
        "    filtered_laptops = laptop_df.copy()\n",
        "    filtered_laptops['Price'] = filtered_laptops['Price'].str.replace(',', '').astype(int)\n",
        "    filtered_laptops = filtered_laptops[filtered_laptops['Price'] <= budget].copy()\n",
        "    # filtered_laptops\n",
        "    # # # Mapping string values 'low', 'medium', 'high' to numerical scores 0, 1, 2\n",
        "    mappings = {'low': 0, 'medium': 1, 'high': 2}\n",
        "\n",
        "    # # # Creating a new column 'Score' in the filtered DataFrame and initializing it to 0\n",
        "    filtered_laptops['Score'] = 0\n",
        "\n",
        "    # # # Iterating over each laptop in the filtered DataFrame to calculate scores based on user requirements\n",
        "    for index, row in filtered_laptops.iterrows():\n",
        "        user_product_match_str = row['laptop_feature']\n",
        "        laptop_values = user_product_match_str\n",
        "        laptop_values = dictionary_present(user_product_match_str)\n",
        "        score = 0\n",
        "\n",
        "    #     # Comparing user requirements with laptop features and updating scores\n",
        "        for key, user_value in user_requirements.items():\n",
        "            # if key.lower() == 'budget':\n",
        "            if key == 'Budget':\n",
        "                continue  # Skipping budget comparison\n",
        "            laptop_value = laptop_values.get(key, None)\n",
        "            # print(key, laptop_value)\n",
        "            laptop_mapping = mappings.get(laptop_value, -1)\n",
        "            # laptop_mapping = mappings.get(laptop_value, -1)\n",
        "            # user_mapping = mappings.get(user_value, -1)\n",
        "            user_mapping = mappings.get(user_value, -1)\n",
        "            if laptop_mapping >= user_mapping:\n",
        "                score += 1  # Incrementing score if laptop value meets or exceeds user value\n",
        "\n",
        "        filtered_laptops.loc[index, 'Score'] = score  # Updating the 'Score' column in the DataFrame\n",
        "\n",
        "    # Sorting laptops by score in descending order and selecting the top 3 products\n",
        "    top_laptops = filtered_laptops.drop('laptop_feature', axis=1)\n",
        "    top_laptops = top_laptops.sort_values('Score', ascending=False).head(3)\n",
        "    top_laptops_json = top_laptops.to_json(orient='records')  # Converting the top laptops DataFrame to JSON format\n",
        "\n",
        "    # top_laptops\n",
        "    return top_laptops_json"
      ],
      "metadata": {
        "id": "ZqKvUdFkcPXF"
      },
      "execution_count": 41,
      "outputs": [],
      "id": "ZqKvUdFkcPXF"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "a0d6dd68"
      },
      "outputs": [],
      "source": [
        "def recommendation_validation(laptop_recommendation):\n",
        "    data = json.loads(laptop_recommendation)\n",
        "    data1 = []\n",
        "    for i in range(len(data)):\n",
        "        if data[i]['Score'] > 2:\n",
        "            data1.append(data[i])\n",
        "\n",
        "    return data1"
      ],
      "id": "a0d6dd68"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6270ac40"
      },
      "outputs": [],
      "source": [
        "def initialize_conv_reco(products):\n",
        "    system_message = f\"\"\"\n",
        "    You are an intelligent laptop gadget expert and you are tasked with the objective to \\\n",
        "    solve the user queries about any product from the catalogue in the user message \\\n",
        "    You should keep the user profile in mind while answering the questions.\\\n",
        "\n",
        "    Start with a brief summary of each laptop in the following format, in decreasing order of price of laptops:\n",
        "    1. <Laptop Name> : <Major specifications of the laptop>, <Price in Rs>\n",
        "    2. <Laptop Name> : <Major specifications of the laptop>, <Price in Rs>\n",
        "\n",
        "    \"\"\"\n",
        "    user_message = f\"\"\" These are the user's products: {products}\"\"\"\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message },\n",
        "                    {\"role\":\"user\",\"content\":user_message}]\n",
        "    # conversation_final = conversation[0]['content']\n",
        "    return conversation"
      ],
      "id": "6270ac40"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10622a7d"
      },
      "source": [
        "# Identify suitable functions for openai function calling\n",
        "\n",
        "\n",
        "- **initialize_conversation**: Sets up the initial system message. Not a candidate for function calling.\n",
        "- **get_chat_completions**: Interacts with OpenAI API. Not a candidate for function calling.\n",
        "- **moderation_check**: Checks for inappropriate content. Could potentially be called by the model for safety checks, but less likely for core requirement processing.\n",
        "- **intent_confirmation_layer**: Checks if user profile is captured. Takes assistant response and outputs a structured result (Yes/No and reason). *Good candidate for function calling.*\n",
        "- **dictionary_present**: Extracts a dictionary from a string. Takes a string and outputs a dictionary. *Good candidate for function calling to parse model output.*\n",
        "- **product_map_layer**: Extracts and classifies laptop features from descriptions. Takes a description and outputs a dictionary. *Good candidate for function calling to process product data.*\n",
        "- **compare_laptops_with_user**: Compares user requirements with laptops and recommends top 3. Takes user requirements (string/dict) and outputs JSON of top laptops. *Good candidate for function calling to get recommendations.*\n",
        "- **recommendation_validation**: Validates laptop recommendations based on a score threshold. Takes JSON of recommendations and outputs filtered list. *Good candidate for function calling to refine recommendations.*\n",
        "- **initialize_conv_reco**: Initializes conversation for recommendations. Sets up system message. Not a candidate for function calling.\n",
        "\n",
        " Below Functions seem like strong candidates as they perform specific data processing tasks.\n",
        "\n",
        " - `intent_confirmation_layer`\n",
        " - `dictionary_present`\n",
        " - `product_map_layer`\n",
        " - `compare_laptops_with_user`\n",
        " - `recommendation_validation`\n",
        "\n",
        ""
      ],
      "id": "10622a7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff170f6c"
      },
      "source": [
        "# Define function specifications for openai\n",
        "\n",
        "Define the necessary function specifications (name, description, parameters, required parameters) in a format that OpenAI's API can understand for the identified functions.\n"
      ],
      "id": "ff170f6c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RcDmP2o88pL",
        "outputId": "53c9b560-47b4-4e5a-9255-a2323f52b72d",
        "collapsed": true
      },
      "source": [
        "import json\n",
        "\n",
        "openai_functions = [\n",
        "    {\n",
        "        \"name\": \"intent_confirmation_layer\",\n",
        "        \"description\": \"Evaluates if the chatbot has clearly captured the user's profile based on specific criteria (GPU intensity, Display quality, Portability, Multitasking, Processing speed, Budget).\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"response_assistant\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The assistant's response containing the captured user requirements.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"response_assistant\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"dictionary_present\",\n",
        "        \"description\": \"Checks if a Python dictionary representing the user's profile is present in the input string and extracts it.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"response\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The input string potentially containing the user's profile dictionary.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"response\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"product_map_layer\",\n",
        "        \"description\": \"Extracts and classifies key features (GPU intensity, Display quality, Portability, Multitasking, Processing speed) from a laptop description.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"laptop_description\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The description of the laptop.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"laptop_description\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"compare_laptops_with_user\",\n",
        "        \"description\": \"Compares user requirements with available laptops, filters by budget, scores them based on matching features, and returns the top 3 recommendations as a JSON string.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"user_req_string\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"A string representation of the user's requirements dictionary. The function will internally parse this to a dictionary.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"user_req_string\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"recommendation_validation\",\n",
        "        \"description\": \"Validates a list of laptop recommendations (in JSON format) and filters them based on a minimum score threshold.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"laptop_recommendation\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"A JSON string representing the list of laptop recommendations, each with a 'Score' key.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"laptop_recommendation\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(json.dumps(openai_functions, indent=2))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"name\": \"intent_confirmation_layer\",\n",
            "    \"description\": \"Evaluates if the chatbot has clearly captured the user's profile based on specific criteria (GPU intensity, Display quality, Portability, Multitasking, Processing speed, Budget).\",\n",
            "    \"parameters\": {\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {\n",
            "        \"response_assistant\": {\n",
            "          \"type\": \"string\",\n",
            "          \"description\": \"The assistant's response containing the captured user requirements.\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"response_assistant\"\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"dictionary_present\",\n",
            "    \"description\": \"Checks if a Python dictionary representing the user's profile is present in the input string and extracts it.\",\n",
            "    \"parameters\": {\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {\n",
            "        \"response\": {\n",
            "          \"type\": \"string\",\n",
            "          \"description\": \"The input string potentially containing the user's profile dictionary.\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"response\"\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"product_map_layer\",\n",
            "    \"description\": \"Extracts and classifies key features (GPU intensity, Display quality, Portability, Multitasking, Processing speed) from a laptop description.\",\n",
            "    \"parameters\": {\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {\n",
            "        \"laptop_description\": {\n",
            "          \"type\": \"string\",\n",
            "          \"description\": \"The description of the laptop.\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"laptop_description\"\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"compare_laptops_with_user\",\n",
            "    \"description\": \"Compares user requirements with available laptops, filters by budget, scores them based on matching features, and returns the top 3 recommendations as a JSON string.\",\n",
            "    \"parameters\": {\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {\n",
            "        \"user_req_string\": {\n",
            "          \"type\": \"string\",\n",
            "          \"description\": \"A string representation of the user's requirements dictionary. The function will internally parse this to a dictionary.\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"user_req_string\"\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"recommendation_validation\",\n",
            "    \"description\": \"Validates a list of laptop recommendations (in JSON format) and filters them based on a minimum score threshold.\",\n",
            "    \"parameters\": {\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {\n",
            "        \"laptop_recommendation\": {\n",
            "          \"type\": \"string\",\n",
            "          \"description\": \"A JSON string representing the list of laptop recommendations, each with a 'Score' key.\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"laptop_recommendation\"\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "id": "0RcDmP2o88pL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b739dd10"
      },
      "source": [
        "# Modify `get chat completions` to handle function calls\n",
        "\n",
        "Modify the `get_chat_completions` function to include the defined function specifications and handle the responses from the OpenAI API when a function call is suggested. This involves parsing the function call request and executing the corresponding Python function.\n"
      ],
      "id": "b739dd10"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa989ae4"
      },
      "source": [
        "import inspect\n",
        "\n",
        "def get_chat_completions(input, json_format=False, functions=None):\n",
        "    MODEL = 'gpt-3.5-turbo'\n",
        "\n",
        "    messages = list(input) # Create a mutable copy of the input messages\n",
        "\n",
        "    if json_format:\n",
        "        system_message_json_output = \"\"\"<<. Return output in JSON format to the key output.>>\"\"\"\n",
        "        if messages and messages[0]['role'] == 'system':\n",
        "            messages[0]['content'] += system_message_json_output\n",
        "        else:\n",
        "            messages.insert(0, {\"role\": \"system\", \"content\": system_message_json_output})\n",
        "\n",
        "\n",
        "    try:\n",
        "        if functions:\n",
        "            chat_completion = openai.chat.completions.create(\n",
        "                model=MODEL,\n",
        "                messages=messages,\n",
        "                functions=functions,\n",
        "                function_call=\"auto\",\n",
        "                seed=1234 # Consistent seed for reproducibility\n",
        "            )\n",
        "        elif json_format:\n",
        "             chat_completion = openai.chat.completions.create(\n",
        "                model=MODEL,\n",
        "                messages=messages,\n",
        "                response_format={ \"type\": \"json_object\"},\n",
        "                seed=1234 # Consistent seed for reproducibility\n",
        "            )\n",
        "        else:\n",
        "            chat_completion = openai.chat.completions.create(\n",
        "                model=MODEL,\n",
        "                messages=messages,\n",
        "                seed=2345 # Different seed when no function calling is involved\n",
        "            )\n",
        "\n",
        "        response_message = chat_completion.choices[0].message\n",
        "\n",
        "        if response_message.function_call:\n",
        "            function_name = response_message.function_call.name\n",
        "            function_args = json.loads(response_message.function_call.arguments)\n",
        "\n",
        "            # Map function names to function objects\n",
        "            available_functions = {\n",
        "                \"intent_confirmation_layer\": intent_confirmation_layer,\n",
        "                \"dictionary_present\": dictionary_present,\n",
        "                \"product_map_layer\": product_map_layer,\n",
        "                \"compare_laptops_with_user\": compare_laptops_with_user,\n",
        "                \"recommendation_validation\": recommendation_validation\n",
        "            }\n",
        "\n",
        "            if function_name in available_functions:\n",
        "                function_to_call = available_functions[function_name]\n",
        "\n",
        "                # Get function signature to check expected parameters\n",
        "                sig = inspect.signature(function_to_call)\n",
        "                params = sig.parameters.keys()\n",
        "\n",
        "                # Filter function_args to only include parameters expected by the function\n",
        "                filtered_args = {k: v for k, v in function_args.items() if k in params}\n",
        "\n",
        "                # Check if all required parameters are present in filtered_args\n",
        "                missing_required_params = [p for p, param in sig.parameters.items() if param.default == inspect.Parameter.empty and p not in filtered_args]\n",
        "\n",
        "                if missing_required_params:\n",
        "                    print(f\"Error: Missing required parameters for function '{function_name}': {missing_required_params}\")\n",
        "                    # Handle this error appropriately, perhaps return an error message to the user\n",
        "                    return \"An error occurred while processing your request due to missing information for the function call.\"\n",
        "\n",
        "                function_response = function_to_call(**filtered_args)\n",
        "\n",
        "                # Append function call and response to messages\n",
        "                messages.append(response_message) # the assistant's function_call message\n",
        "                messages.append(\n",
        "                    {\n",
        "                        \"role\": \"function\",\n",
        "                        \"name\": function_name,\n",
        "                        \"content\": json.dumps(function_response) if isinstance(function_response, (dict, list)) else str(function_response),\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # Make another API call with function output\n",
        "                second_response = openai.chat.completions.create(\n",
        "                    model=MODEL,\n",
        "                    messages=messages,\n",
        "                    seed=4567 # Different seed for the second call\n",
        "                )\n",
        "                return second_response.choices[0].message.content\n",
        "            else:\n",
        "                print(f\"Error: Function '{function_name}' not found.\")\n",
        "                return \"An error occurred: The requested function is not available.\"\n",
        "        else:\n",
        "            if json_format:\n",
        "                return json.loads(response_message.content)\n",
        "            else:\n",
        "                return response_message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during get_chat_completions: {e}\")\n",
        "        return \"An error occurred while processing your request. Please try again.\""
      ],
      "execution_count": 38,
      "outputs": [],
      "id": "fa989ae4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e07a229"
      },
      "source": [
        "# Integrate function calling into `dialogue mgmt system`\n",
        "\n",
        "Modify the `dialogue_mgmt_system` function to use the updated `get_chat_completions` function and manage the conversation flow based on whether the model requests a function call or provides a regular message.\n"
      ],
      "id": "2e07a229"
    },
    {
      "cell_type": "code",
      "source": [
        "def dialogue_mgmt_system():\n",
        "    global top_3_laptops\n",
        "\n",
        "    conversation_history = initialize_conversation()\n",
        "\n",
        "    # Initial welcome message\n",
        "    welcome_message = get_chat_completions(conversation_history)\n",
        "    display(welcome_message + '\\n')\n",
        "\n",
        "    top_3_laptops = None  # Initialize top_3_laptops to None\n",
        "\n",
        "    user_input = ''\n",
        "\n",
        "    while user_input.lower() != \"exit\":\n",
        "        user_input = input(\"You: \")  # Prompt the user for their input\n",
        "\n",
        "        moderation_status = moderation_check(user_input)\n",
        "        if moderation_status == 'Flagged':\n",
        "            display(\"Sorry, your message has been flagged. Please restart the conversation.\")\n",
        "            break\n",
        "\n",
        "        # Append user input to the conversation history for processing\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        if top_3_laptops is None:\n",
        "            # Gather initial response while determining user intent\n",
        "            assistant_response = get_chat_completions(conversation_history, functions=openai_functions)\n",
        "\n",
        "            if isinstance(assistant_response, str):  # Check if we received valid text response\n",
        "                conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "                print(\"Assistant:\", assistant_response + '\\n')\n",
        "\n",
        "                # After the assistant provides the response, check if it contains the user requirements dictionary\n",
        "                user_req_dict_str = dictionary_present(assistant_response)\n",
        "                if user_req_dict_str:\n",
        "                    try:\n",
        "                        user_req_dict = json.loads(user_req_dict_str)\n",
        "                        # Now call compare_laptops_with_user with the extracted dictionary\n",
        "                        top_3_laptops = compare_laptops_with_user(user_req_dict)\n",
        "                        print('\\n' + \"Products have been successfully fetched!\" + '\\n')\n",
        "                        print(\"Here are some laptop recommendations based on your preferences:\" + '\\n')\n",
        "                        # Initialize recommendation conversation\n",
        "                        recommendation_conv = initialize_conv_reco(top_3_laptops)\n",
        "                        # Continue the conversation with the recommendation summary\n",
        "                        recommendation_summary = get_chat_completions(recommendation_conv)\n",
        "                        print(\"Assistant:\", recommendation_summary + '\\n')\n",
        "\n",
        "                    except json.JSONDecodeError:\n",
        "                        print(\"Could not parse the user requirements dictionary from the assistant's response.\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"An error occurred while getting recommendations: {e}\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                # Handle unexpected non-string responses gracefully\n",
        "                print(\"Received an unexpected response:\", assistant_response)\n",
        "\n",
        "        else:\n",
        "            # If in the recommendation phase, continue with follow-up questions\n",
        "            follow_up_response = get_chat_completions(conversation_history)\n",
        "\n",
        "            if isinstance(follow_up_response, str):\n",
        "                conversation_history.append({\"role\": \"assistant\", \"content\": follow_up_response})\n",
        "                print(\"Assistant:\", follow_up_response + '\\n')\n",
        "            else:\n",
        "                print(\"An issue occurred in the recommendation phase:\", follow_up_response)"
      ],
      "metadata": {
        "id": "UbTncujhiIjS"
      },
      "id": "UbTncujhiIjS",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue_mgmt_system()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "id": "vaXbpK2W-C0l",
        "outputId": "69ad3be7-d6e1-454e-be73-f17035e8bae6"
      },
      "id": "vaXbpK2W-C0l",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Hello! Welcome to the laptop recommendation assistant. Please share with me your requirements so that I can help you find the best laptop that suits your needs.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: I want a gaming laptop under 100000\n",
            "ModerationCreateResponse(id='modr-BpY0eFTvvDRRffWgXNeiAz9YcyoQi', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=None, illicit_violent=None, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_applied_input_types=None, category_scores=CategoryScores(harassment=4.83349049318349e-06, harassment_threatening=2.344178756175097e-05, hate=9.738815833770786e-07, hate_threatening=1.3695890856979531e-06, illicit=None, illicit_violent=None, self_harm=0.0008077799575403333, self_harm_instructions=0.0006937571451999247, self_harm_intent=0.00757378526031971, sexual=2.2231339244171977e-05, sexual_minors=1.0951660442515276e-05, violence=3.0410392355406657e-05, violence_graphic=1.1836353223770857e-05, self-harm=0.0008077799575403333, sexual/minors=1.0951660442515276e-05, hate/threatening=1.3695890856979531e-06, violence/graphic=1.1836353223770857e-05, self-harm/intent=0.00757378526031971, self-harm/instructions=0.0006937571451999247, harassment/threatening=2.344178756175097e-05), flagged=False)])\n",
            "Assistant: Great! I can help you find a gaming laptop under 100000 INR. To assist you better, could you please specify the key features that are important to you in a gaming laptop? This will help me find the best match for your needs.\n",
            "\n",
            "You: high performance, great display\n",
            "ModerationCreateResponse(id='modr-BpY14Y4nk8CxA9OlONy99uGdWWKnS', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=None, illicit_violent=None, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_applied_input_types=None, category_scores=CategoryScores(harassment=4.0031773096416146e-06, harassment_threatening=6.749435669917148e-06, hate=1.4311055451798893e-07, hate_threatening=4.1118244098470313e-07, illicit=None, illicit_violent=None, self_harm=1.9069082554779015e-05, self_harm_instructions=5.851081004948355e-05, self_harm_intent=1.7448361177230254e-05, sexual=4.736445771413855e-05, sexual_minors=4.0836019365997345e-07, violence=5.556809264817275e-05, violence_graphic=7.65737331676064e-06, self-harm=1.9069082554779015e-05, sexual/minors=4.0836019365997345e-07, hate/threatening=4.1118244098470313e-07, violence/graphic=7.65737331676064e-06, self-harm/intent=1.7448361177230254e-05, self-harm/instructions=5.851081004948355e-05, harassment/threatening=6.749435669917148e-06), flagged=False)])\n",
            "Assistant: Thank you for sharing your requirements. For a gaming laptop with high performance and a great display, I would suggest a laptop with high GPU intensity and high Display quality. \n",
            "\n",
            "To proceed further, I have a few questions:\n",
            "1. Do you prefer a laptop that is highly portable or are you okay with a heavier laptop for better performance?\n",
            "2. How important is multitasking capability for you while gaming?\n",
            "3. Are you looking for a laptop with extremely fast processing speed?\n",
            "\n",
            "Understanding these aspects will help me recommend the best gaming laptop for you. Let me know your preferences.\n",
            "\n",
            "You: portability is not a concern, need high multitasking capability and fast processing speed \n",
            "ModerationCreateResponse(id='modr-BpY289n9o75PS9gCL1wYAJXgGEToU', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=None, illicit_violent=None, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_applied_input_types=None, category_scores=CategoryScores(harassment=3.384633964742534e-05, harassment_threatening=2.531311292841565e-05, hate=2.6745030936581315e-06, hate_threatening=2.361164888498024e-06, illicit=None, illicit_violent=None, self_harm=1.980626257136464e-05, self_harm_instructions=4.9501082685310394e-05, self_harm_intent=4.5389471779344603e-05, sexual=3.535213909344748e-05, sexual_minors=6.5014946812880225e-06, violence=0.0007399116875603795, violence_graphic=1.966895069926977e-05, self-harm=1.980626257136464e-05, sexual/minors=6.5014946812880225e-06, hate/threatening=2.361164888498024e-06, violence/graphic=1.966895069926977e-05, self-harm/intent=4.5389471779344603e-05, self-harm/instructions=4.9501082685310394e-05, harassment/threatening=2.531311292841565e-05), flagged=False)])\n",
            "Assistant: Thank you for providing that information. Based on your requirements, I would assign high values to Multitasking and Processing speed in the laptop. \n",
            "\n",
            "Now, to complete the user profile, could you please specify your maximum budget for the gaming laptop? This will allow me to find options that fit within your price range while meeting the specified requirements.\n",
            "\n",
            "You: 105000\n",
            "ModerationCreateResponse(id='modr-BpY2H2FQV6pAlOeDPuqmuIAcoQnMn', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=None, illicit_violent=None, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_applied_input_types=None, category_scores=CategoryScores(harassment=0.00023585815506521612, harassment_threatening=0.00024727036361582577, hate=0.0005307937972247601, hate_threatening=0.0001466432586312294, illicit=None, illicit_violent=None, self_harm=3.668306817417033e-05, self_harm_instructions=4.036315658595413e-05, self_harm_intent=6.117307930253446e-05, sexual=0.0019882803317159414, sexual_minors=0.0009846494067460299, violence=0.0002517612592782825, violence_graphic=3.777535312110558e-05, self-harm=3.668306817417033e-05, sexual/minors=0.0009846494067460299, hate/threatening=0.0001466432586312294, violence/graphic=3.777535312110558e-05, self-harm/intent=6.117307930253446e-05, self-harm/instructions=4.036315658595413e-05, harassment/threatening=0.00024727036361582577), flagged=False)])\n",
            "Assistant: Great! With a budget of 105000 INR, I will now update the user profile based on your requirements.\n",
            "\n",
            "{'GPU intensity': 'high', 'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'high', 'Budget': 105000}\n",
            "\n",
            "You: looks good, give me recommendations\n",
            "ModerationCreateResponse(id='modr-BpY2adpbZBQfpNk7MAHbyw7qHvQCN', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=None, illicit_violent=None, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_applied_input_types=None, category_scores=CategoryScores(harassment=4.057216938235797e-05, harassment_threatening=7.17991770216031e-06, hate=8.06438947620336e-06, hate_threatening=5.221994570092647e-07, illicit=None, illicit_violent=None, self_harm=5.688664714398328e-06, self_harm_instructions=3.50398431692156e-06, self_harm_intent=1.7959078832063824e-05, sexual=0.0001299155701417476, sexual_minors=1.0836290130100679e-05, violence=5.0383918278384954e-05, violence_graphic=1.1867820830957498e-05, self-harm=5.688664714398328e-06, sexual/minors=1.0836290130100679e-05, hate/threatening=5.221994570092647e-07, violence/graphic=1.1867820830957498e-05, self-harm/intent=1.7959078832063824e-05, self-harm/instructions=3.50398431692156e-06, harassment/threatening=7.17991770216031e-06), flagged=False)])\n",
            "An error occurred during get_chat_completions: name 'response_dict_n' is not defined\n",
            "Assistant: An error occurred while processing your request. Please try again.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-40-3339482843.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdialogue_mgmt_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-39-3906708896.py\u001b[0m in \u001b[0;36mdialogue_mgmt_system\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prompt the user for their input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmoderation_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoderation_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BaXc8t_V-Kgw"
      },
      "id": "BaXc8t_V-Kgw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5a5e110",
        "outputId": "299e0651-6c15-4fa7-e5ab-cafadfeeb04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "dialogue_mgmt_system()"
      ],
      "id": "d5a5e110",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello! Welcome to the laptop recommendation assistant. Please share with me your requirements so that I can help you find the best laptop that suits your needs.\\n'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModerationCreateResponse(id='modr-BpY9bfxGSHxbI9wH7Lao44uS9F8bw', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=None, illicit_violent=None, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_applied_input_types=None, category_scores=CategoryScores(harassment=1.6026916682676529e-06, harassment_threatening=1.7772945284377784e-06, hate=3.287800609541591e-07, hate_threatening=1.1422570622698913e-07, illicit=None, illicit_violent=None, self_harm=5.633037289953791e-07, self_harm_instructions=9.663665878179017e-06, self_harm_intent=5.5395016715920065e-06, sexual=2.3979517209227197e-05, sexual_minors=2.9572863695648266e-06, violence=1.2767794942192268e-05, violence_graphic=2.5278326575062238e-05, self-harm=5.633037289953791e-07, sexual/minors=2.9572863695648266e-06, hate/threatening=1.1422570622698913e-07, violence/graphic=2.5278326575062238e-05, self-harm/intent=5.5395016715920065e-06, self-harm/instructions=9.663665878179017e-06, harassment/threatening=1.7772945284377784e-06), flagged=False)])\n",
            "Assistant: Great to hear that you're looking for a gaming laptop under 1 lakh INR. To find the best gaming laptop for you, I need to understand your preferences better. \n",
            "\n",
            "Do you have any specific requirements or features in mind that you would like to prioritize in the gaming laptop? This will help me tailor the recommendations to your needs.\n",
            "\n",
            "ModerationCreateResponse(id='modr-BpYA5DOpagKeR8nnnbDJYh6c4AVqJ', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=None, illicit_violent=None, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_applied_input_types=None, category_scores=CategoryScores(harassment=6.513442349387333e-05, harassment_threatening=5.660665556206368e-05, hate=4.3002237362088636e-06, hate_threatening=1.1359916243236512e-06, illicit=None, illicit_violent=None, self_harm=1.617997077119071e-05, self_harm_instructions=8.33758240332827e-05, self_harm_intent=3.106290751020424e-05, sexual=7.140083471313119e-05, sexual_minors=4.980970516044181e-06, violence=0.0002794447646010667, violence_graphic=4.961819649906829e-05, self-harm=1.617997077119071e-05, sexual/minors=4.980970516044181e-06, hate/threatening=1.1359916243236512e-06, violence/graphic=4.961819649906829e-05, self-harm/intent=3.106290751020424e-05, self-harm/instructions=8.33758240332827e-05, harassment/threatening=5.660665556206368e-05), flagged=False)])\n",
            "Assistant: Based on your requirements for a gaming laptop under 1 lakh with high processing speed and great display, while portability is not a concern, I can infer the following values for your laptop profile:\n",
            "\n",
            "- GPU intensity: \n",
            "- Display quality: high\n",
            "- Portability: low\n",
            "- Multitasking: \n",
            "- Processing speed: high\n",
            "- Budget: 100000\n",
            "\n",
            "I will now ask a few more questions to clarify and finalize the values for the remaining keys. \n",
            "\n",
            "Do you prioritize multitasking on your gaming laptop, or is it more important for you to have high GPU intensity?\n",
            "\n",
            "An error occurred while getting recommendations: the JSON object must be str, bytes or bytearray, not dict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOq94CChBx3x"
      },
      "id": "aOq94CChBx3x",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}